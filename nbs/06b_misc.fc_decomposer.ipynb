{
 "cells": [
  {
   "cell_type": "raw",
   "id": "452d040d",
   "metadata": {},
   "source": [
    "---\n",
    "description: Factorize heavy FC layers into smaller ones\n",
    "output-file: fc_decomposer.html\n",
    "title: Fully-Connected Layers Decomposer\n",
    "skip_showdoc: true\n",
    "skip_exec: true\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd975549",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp misc.fc_decomposer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6802a5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "from nbdev.showdoc import *\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f88207",
   "metadata": {},
   "source": [
    "We can factorize our big fully-connected layers and replace them by an approximation of two smaller layers. The idea is to make an SVD decomposition of the weight matrix, which will express the original matrix in a product of 3 matrices: $U \\Sigma V^T$\n",
    "With $\\Sigma$ being a diagonal matrix with non-negative values along its diagonal (the singular values). We then define a value $k$ of singular values to keep and modify matrices $U$ and $V^T$ accordingly. The resulting will be an approximation of the initial matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d50bd48",
   "metadata": {},
   "source": [
    "![](imgs/svd.png \"SVD Decomposition\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbccd4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nathan/opt/miniconda3/envs/nbdev/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6524ac31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class FC_Decomposer:\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def decompose(self, model, percent_removed=0.5):\n",
    "\n",
    "        new_model = copy.deepcopy(model)\n",
    "\n",
    "        module_names = list(new_model._modules)\n",
    "\n",
    "        for k, name in enumerate(module_names):\n",
    "\n",
    "            if len(list(new_model._modules[name]._modules)) > 0:\n",
    "                new_model._modules[name] = self.decompose(new_model._modules[name], percent_removed)\n",
    "\n",
    "            else:\n",
    "                if isinstance(new_model._modules[name], nn.Linear):\n",
    "                    # Folded BN\n",
    "                    layer = self.SVD(new_model._modules[name], percent_removed)\n",
    "\n",
    "                    # Replace old weight values\n",
    "                    new_model._modules[name] = layer # Replace the FC Layer by the decomposed version\n",
    "        return new_model\n",
    "\n",
    "\n",
    "    def SVD(self, layer, percent_removed):\n",
    "\n",
    "        W = layer.weight.data\n",
    "        U, S, V = torch.svd(W)\n",
    "        L = int((1.-percent_removed)*U.shape[0])\n",
    "        W1 = U[:,:L]\n",
    "        W2 = torch.diag(S[:L]) @ V[:,:L].t()\n",
    "        layer_1 = nn.Linear(in_features=layer.in_features, \n",
    "                    out_features=L, bias=False)\n",
    "        layer_1.weight.data = W2\n",
    "\n",
    "        layer_2 = nn.Linear(in_features=L, \n",
    "                    out_features=layer.out_features, bias=True)\n",
    "        layer_2.weight.data = W1\n",
    "\n",
    "        if layer.bias.data is None: \n",
    "            layer_2.bias.data = torch.zeros(*layer.out_features.shape)\n",
    "        else:\n",
    "            layer_2.bias.data = layer.bias.data\n",
    "\n",
    "        return nn.Sequential(layer_1, layer_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50222d43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### FC_Decomposer.decompose\n",
       "\n",
       ">      FC_Decomposer.decompose (model, percent_removed=0.5)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### FC_Decomposer.decompose\n",
       "\n",
       ">      FC_Decomposer.decompose (model, percent_removed=0.5)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(FC_Decomposer.decompose)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca024eed",
   "metadata": {},
   "source": [
    "A tutorial about how to use the `FC_Decomposer` functionalities can be found [here](https://nathanhubens.github.io/fasterai/tutorial.fc_decomposer.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
